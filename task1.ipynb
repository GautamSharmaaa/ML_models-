{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install kaggle"
      ],
      "metadata": {
        "id": "3eiUmAWQmhE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "6zOAykEqmllO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jessicali9530/stanford-cars-dataset --unzip -p /content/stanford_cars\n"
      ],
      "metadata": {
        "id": "Thn7z2j0mlgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nE3GFxKNkMfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# Select layers for feature extraction\n",
        "layer_names = ['block1_conv2', 'block3_conv3', 'block5_conv3']\n",
        "layer_outputs = [base_model.get_layer(layer).output for layer in layer_names]\n",
        "feature_extractor = Model(inputs=base_model.input, outputs=layer_outputs)\n",
        "\n",
        "# Load Stanford Car dataset images\n",
        "car_images_path = \"/content/stanford_cars/cars_test/cars_test\"  # Change to \"cars_train/cars_train\" if needed\n",
        "image_files = [f for f in os.listdir(car_images_path) if f.endswith('.jpg')]\n",
        "\n",
        "# Ensure there are at least 5 images before sampling\n",
        "if len(image_files) < 5:\n",
        "    print(f\"Warning: Only {len(image_files)} images found. Selecting all available images.\")\n",
        "    random_images = image_files  # Use all available images\n",
        "else:\n",
        "    random_images = random.sample(image_files, 5)  # Select 5 random images\n",
        "\n"
      ],
      "metadata": {
        "id": "zKPoEjfjmkRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_files = [f for f in os.listdir(car_images_path) if f.endswith('.jpg')]\n",
        "random_images = random.sample(image_files, 5)  # Select 5 random images"
      ],
      "metadata": {
        "id": "8AD7ZeUkpAPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to preprocess and extract features\n",
        "def extract_and_visualize(image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Extract features\n",
        "    feature_maps = feature_extractor.predict(img_array)\n",
        "\n",
        "    # Display original image\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Display feature maps\n",
        "    for i, feature_map in enumerate(feature_maps):\n",
        "        feature_map = np.squeeze(feature_map, axis=0)  # Remove batch dimension\n",
        "        feature_map = np.mean(feature_map, axis=-1)  # Average over channels\n",
        "\n",
        "        plt.subplot(1, 4, i+2)\n",
        "        plt.imshow(feature_map, cmap='viridis')\n",
        "        plt.title(f\"{layer_names[i]} Output\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "CbI8PA0fmkXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Process 5 random images\n",
        "for img_file in random_images:\n",
        "    extract_and_visualize(os.path.join(car_images_path, img_file))"
      ],
      "metadata": {
        "id": "Nc-jWqhwmhCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ziUdo01_l2Lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/Mask Wearing.v4-raw.yolov5pytorch.zip\"\n"
      ],
      "metadata": {
        "id": "FMPGIuTZqO4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "!cd yolov5\n",
        "!pip install -r requirements.txt  # install"
      ],
      "metadata": {
        "id": "qJYwYt9zqO7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/train.py --img 640 --batch 16 --epochs 50 --data /content/data.yaml --weights yolov5s.pt --device 0 --project runs/train --name mask_model --save-period 5\n"
      ],
      "metadata": {
        "id": "z8ptqg3XqO_v",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train\n",
        "\n"
      ],
      "metadata": {
        "id": "FfxV36Ust70a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/val.py --data /content/data.yaml --weights /content/runs/train/mask_model/weights/best.pt --img 640\n"
      ],
      "metadata": {
        "id": "vWyBKhIAyVoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --weights /content/runs/train/mask_model/weights/best.pt --img 640 --source /content/test/images --conf 0.25 --iou 0.45\n"
      ],
      "metadata": {
        "id": "4q663cB3yZEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/test\n"
      ],
      "metadata": {
        "id": "FZ_9RC4F6tBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "for image_path in glob.glob('/content/yolov5/runs/detect/exp2/*.jpg'):\n",
        "    display(Image(filename=image_path))\n"
      ],
      "metadata": {
        "id": "tgIxsBkS65mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/val.py --data /content/data.yaml --weights /content/runs/train/mask_model/weights/best.pt --task val --save-json --save-conf --name mask_model_val"
      ],
      "metadata": {
        "id": "MceqRPGc7YCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/yolov5/runs/val/mask_model_val/confusion_matrix.png')\n"
      ],
      "metadata": {
        "id": "dqMfegiKA-p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k739ohAeA-sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4DYAKoSA-u5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}